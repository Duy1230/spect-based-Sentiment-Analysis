{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q seqeval==1.2.2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T15:55:43.612555Z","iopub.execute_input":"2025-02-13T15:55:43.612858Z","iopub.status.idle":"2025-02-13T15:55:50.800632Z","shell.execute_reply.started":"2025-02-13T15:55:43.612831Z","shell.execute_reply":"2025-02-13T15:55:50.799802Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!pip install -q datasets==3.2.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T15:55:50.801975Z","iopub.execute_input":"2025-02-13T15:55:50.802285Z","iopub.status.idle":"2025-02-13T15:55:54.154218Z","shell.execute_reply.started":"2025-02-13T15:55:50.802253Z","shell.execute_reply":"2025-02-13T15:55:54.153295Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"!pip install -q evaluate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T15:55:54.155867Z","iopub.execute_input":"2025-02-13T15:55:54.156108Z","iopub.status.idle":"2025-02-13T15:55:57.835647Z","shell.execute_reply.started":"2025-02-13T15:55:54.156085Z","shell.execute_reply":"2025-02-13T15:55:57.834701Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## Aspect Term Extraction","metadata":{}},{"cell_type":"code","source":"from seqeval.metrics import accuracy_score\nfrom datasets import load_dataset\nfrom transformers import (AutoTokenizer,\n                          DataCollatorForTokenClassification,\n                          AutoModelForTokenClassification)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T14:39:45.066659Z","iopub.execute_input":"2025-02-13T14:39:45.066897Z","iopub.status.idle":"2025-02-13T14:40:06.522295Z","shell.execute_reply.started":"2025-02-13T14:39:45.066877Z","shell.execute_reply":"2025-02-13T14:40:06.521664Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"ds = load_dataset(\"thainq107/abte-restaurants\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T14:40:06.523057Z","iopub.execute_input":"2025-02-13T14:40:06.523592Z","iopub.status.idle":"2025-02-13T14:40:11.204677Z","shell.execute_reply.started":"2025-02-13T14:40:06.523559Z","shell.execute_reply":"2025-02-13T14:40:11.204025Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/454 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b4c7ca8f55d4937988b3dceb6884f8f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/183k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e685cb394ea4168be1f1472bec0c740"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/61.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d7a0adafb6a849fcb53d6b600d10a4ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/3602 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44791d1c0856464f98d644db303ec6cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1119 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1479c2f8cba9451e9c9fec44637b0eb0"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"\" \".join(ds['train'][1][\"Tokens\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T15:13:10.248115Z","iopub.execute_input":"2025-02-13T15:13:10.248476Z","iopub.status.idle":"2025-02-13T15:13:10.254555Z","shell.execute_reply.started":"2025-02-13T15:13:10.248443Z","shell.execute_reply":"2025-02-13T15:13:10.253487Z"}},"outputs":[{"execution_count":78,"output_type":"execute_result","data":{"text/plain":"'To be completely fair , the only redeeming factor was the food , which was above average , but could \"nt\" make up for all the other deficiencies of Teodora .'"},"metadata":{}}],"execution_count":78},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")\n\ndef tokenize_and_align_labels(examples):\n    tokenized_inputs = []\n    labels = []\n    for tokens, tags in zip(examples['Tokens'], examples['Tags']):\n        # tokens = tokens.replace(\"'\", \"\").strip(\"][\").split(', ')\n        # tags = tags.strip('][').split(', ')\n\n        bert_tokens = []\n        bert_tags = []\n        for i in range(len(tokens)):\n            t = tokenizer.tokenize(tokens[i])\n            bert_tokens += t\n            bert_tags += [int(tags[i])]*len(t)\n\n        bert_ids = tokenizer.convert_tokens_to_ids(bert_tokens)\n\n        tokenized_inputs.append(bert_ids)\n        labels.append(bert_tags)\n\n    return {\n        'input_ids': tokenized_inputs ,\n        'labels': labels\n    }\n\npreprocessed_ds = ds.map(tokenize_and_align_labels, batched = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T14:40:11.214356Z","iopub.execute_input":"2025-02-13T14:40:11.214623Z","iopub.status.idle":"2025-02-13T14:40:16.089435Z","shell.execute_reply.started":"2025-02-13T14:40:11.214602Z","shell.execute_reply":"2025-02-13T14:40:16.088499Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7305849359af45f29647bce52077683a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb32d3887c4b47da8e25515b9a5aa035"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f60c10bc56e64eedb5ba3eba66c7916a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c513064659814c68bf5eac44a8d020cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3602 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a870854d7084031b8f3cd8591cc5cf6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1119 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d79069273b8949948ce840cce0f84afb"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"preprocessed_ds['train'][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T14:40:16.091285Z","iopub.execute_input":"2025-02-13T14:40:16.091578Z","iopub.status.idle":"2025-02-13T14:40:16.098013Z","shell.execute_reply.started":"2025-02-13T14:40:16.091555Z","shell.execute_reply":"2025-02-13T14:40:16.096941Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"{'Tokens': ['But', 'the', 'staff', 'was', 'so', 'horrible', 'to', 'us', '.'],\n 'Tags': ['0', '0', '1', '0', '0', '0', '0', '0', '0'],\n 'Polarities': ['-1', '-1', '0', '-1', '-1', '-1', '-1', '-1', '-1'],\n 'input_ids': [2021, 1996, 3095, 2001, 2061, 9202, 2000, 2149, 1012],\n 'labels': [0, 0, 1, 0, 0, 0, 0, 0, 0]}"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T14:40:16.098784Z","iopub.execute_input":"2025-02-13T14:40:16.098977Z","iopub.status.idle":"2025-02-13T14:40:16.171094Z","shell.execute_reply.started":"2025-02-13T14:40:16.098960Z","shell.execute_reply":"2025-02-13T14:40:16.170372Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import numpy as np\nfrom seqeval.metrics import accuracy_score, f1_score, classification_report\n\ndef compute_metrics(p):\n    predictions, labels = p\n    predictions = np.argmax(predictions, axis=2)\n\n    # Remove ignored index (special tokens) and convert to labels\n    true_predictions = [\n        [id2label[p] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n    true_labels = [\n        [id2label[l] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n\n    # Calculate F1 score (macro-averaged)\n    results = f1_score(true_labels, true_predictions, average=\"macro\")  # Add average=\"macro\"\n\n    # Optional: Get a full classification report (precision, recall, F1, support)\n    report = classification_report(true_labels, true_predictions)\n    print(report)  # Print the report for detailed analysis\n\n    return {\"f1\": results}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T14:40:16.171974Z","iopub.execute_input":"2025-02-13T14:40:16.172227Z","iopub.status.idle":"2025-02-13T14:40:16.185083Z","shell.execute_reply.started":"2025-02-13T14:40:16.172206Z","shell.execute_reply":"2025-02-13T14:40:16.184374Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"id2label = {\n    0: \"O\",\n    1: \"B-Term\",\n    2: \"I-Term\"\n}\nlabel2id = {\n    \"O\": 0,\n    \"B-Term\": 1,\n    \"I-Term\": 2\n}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T14:40:16.185913Z","iopub.execute_input":"2025-02-13T14:40:16.186191Z","iopub.status.idle":"2025-02-13T14:40:16.202614Z","shell.execute_reply.started":"2025-02-13T14:40:16.186159Z","shell.execute_reply":"2025-02-13T14:40:16.201888Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom transformers import TrainingArguments, Trainer, AutoConfig, PreTrainedModel\nfrom transformers.modeling_outputs import TokenClassifierOutput","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T14:40:16.203416Z","iopub.execute_input":"2025-02-13T14:40:16.203614Z","iopub.status.idle":"2025-02-13T14:40:18.834517Z","shell.execute_reply.started":"2025-02-13T14:40:16.203596Z","shell.execute_reply":"2025-02-13T14:40:18.833622Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"class ResidualBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding='same'):\n        super(ResidualBlock, self).__init__()\n        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, stride, padding)\n        self.bn1 = nn.BatchNorm1d(out_channels)\n        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size, stride, padding)\n        self.bn2 = nn.BatchNorm1d(out_channels)\n\n        self.shortcut = nn.Sequential()\n        if in_channels != out_channels: # Projection if dimensions change\n            self.shortcut = nn.Sequential(\n                nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=1, padding='same'),  # 1x1 conv for projection\n                nn.BatchNorm1d(out_channels)\n            )\n    def forward(self, x):\n        residual = x\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out += self.shortcut(residual)  # Add shortcut connection\n        out = F.relu(out)\n        return out\n\n\nclass Conv1dATEModel(PreTrainedModel):\n    config_class = AutoConfig  # Use AutoConfig for compatibility\n\n    def __init__(self, config):\n        super().__init__(config)\n        self.config = config\n        self.embedding = nn.Embedding(config.vocab_size, config.hidden_size)\n        self.in_channels = config.hidden_size\n        \n         # --- Residual Blocks ---\n        self.res_block1 = ResidualBlock(self.in_channels, config.hidden_size, kernel_size=3)\n        self.res_block2 = ResidualBlock(config.hidden_size, config.hidden_size, kernel_size=3)\n        self.res_block3 = ResidualBlock(config.hidden_size, config.hidden_size, kernel_size=3)\n        self.dropout = nn.Dropout(0.2)\n        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n\n        # Weight initialization (important!)\n        self.init_weights()  # Initialize weights as HuggingFace does\n\n\n    def forward(self, input_ids=None, attention_mask=None, labels=None):\n        # Embedding layer\n        embeddings = self.embedding(input_ids)\n\n        # Conv1d expects input (batch_size, channels, sequence_length)\n        #   - embeddings is (batch_size, sequence_length, hidden_size)\n        #   - Transpose to (batch_size, hidden_size, sequence_length)\n        embeddings = embeddings.transpose(1, 2)\n\n        # Convolutional layers\n        x = self.res_block1(embeddings)\n        x = self.res_block2(x)\n        x = self.res_block3(x)\n\n        # Transpose back to (batch_size, sequence_length, hidden_size)\n        x = x.transpose(1, 2)\n\n        # Dropout and classification\n        x = self.dropout(x)\n        logits = self.classifier(x)\n\n        # Calculate loss (if labels are provided)\n        loss = None\n        if labels is not None:\n            loss_fct = nn.CrossEntropyLoss()\n            # Only keep active parts of the loss\n            if attention_mask is not None:\n                active_loss = attention_mask.view(-1) == 1\n                active_logits = logits.view(-1, self.config.num_labels)\n                active_labels = torch.where(\n                    active_loss, labels.view(-1), torch.tensor(loss_fct.ignore_index).type_as(labels)\n                )\n                loss = loss_fct(active_logits, active_labels)\n            else:\n                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n\n        return TokenClassifierOutput(\n            loss=loss,\n            logits=logits\n        )\n\n    def init_weights(self):\n        # Use the same initialization as Hugging Face models\n        self.apply(self._init_weights)\n\n    def _init_weights(self, module):\n        \"\"\"Initialize the weights like the original models\"\"\"\n        if isinstance(module, nn.Linear):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.bias is not None:\n                module.bias.data.zero_()\n        elif isinstance(module, nn.Embedding):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.padding_idx is not None:\n                module.weight.data[module.padding_idx].zero_()\n        elif isinstance(module, nn.Conv1d):\n             module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n             if module.bias is not None:\n                module.bias.data.zero_()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T15:09:04.848818Z","iopub.execute_input":"2025-02-13T15:09:04.849131Z","iopub.status.idle":"2025-02-13T15:09:04.861870Z","shell.execute_reply.started":"2025-02-13T15:09:04.849107Z","shell.execute_reply":"2025-02-13T15:09:04.861027Z"}},"outputs":[],"execution_count":69},{"cell_type":"code","source":"config = AutoConfig.from_pretrained(\n    \"distilbert/distilbert-base-uncased\",  # Base config on a known model\n    num_labels=3,\n    id2label=id2label,\n    label2id=label2id,\n    initializer_range=0.02,  # Standard initialization range\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T15:09:08.911661Z","iopub.execute_input":"2025-02-13T15:09:08.911950Z","iopub.status.idle":"2025-02-13T15:09:09.004750Z","shell.execute_reply.started":"2025-02-13T15:09:08.911927Z","shell.execute_reply":"2025-02-13T15:09:09.004102Z"}},"outputs":[],"execution_count":70},{"cell_type":"code","source":"model_conv1d = Conv1dATEModel(config=config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T15:09:09.222535Z","iopub.execute_input":"2025-02-13T15:09:09.222783Z","iopub.status.idle":"2025-02-13T15:09:09.726124Z","shell.execute_reply.started":"2025-02-13T15:09:09.222763Z","shell.execute_reply":"2025-02-13T15:09:09.725404Z"}},"outputs":[],"execution_count":71},{"cell_type":"code","source":"\nmodel_pretrained = AutoModelForTokenClassification.from_pretrained(\n    \"distilbert/distilbert-base-uncased\",\n    num_labels =3, id2label=id2label , label2id=label2id\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T14:40:19.516747Z","iopub.execute_input":"2025-02-13T14:40:19.517023Z","iopub.status.idle":"2025-02-13T14:40:21.413229Z","shell.execute_reply.started":"2025-02-13T14:40:19.516997Z","shell.execute_reply":"2025-02-13T14:40:21.412457Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aeea641334144a48866ccbe2654d6976"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"import os\nos.environ['WANDB_DISABLED'] = 'true'\nfrom transformers import TrainingArguments, Trainer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T14:40:21.414151Z","iopub.execute_input":"2025-02-13T14:40:21.414472Z","iopub.status.idle":"2025-02-13T14:40:21.418866Z","shell.execute_reply.started":"2025-02-13T14:40:21.414442Z","shell.execute_reply":"2025-02-13T14:40:21.417961Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"distilbert-base-uncased\",\n    learning_rate =2e-5,\n    per_device_train_batch_size =16,\n    per_device_eval_batch_size =16,\n    num_train_epochs =5,\n    weight_decay =0.01,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True\n)\n\ntrainer = Trainer(\n    model=model_pretrained ,\n    args=training_args ,\n    train_dataset=preprocessed_ds[\"train\"],\n    eval_dataset=preprocessed_ds[\"test\"],\n    processing_class=tokenizer ,\n    data_collator=data_collator ,\n    compute_metrics=compute_metrics ,\n)\n\ntrainer.train()\ntrainer.save_model(\"abte-restaurants-distilbert-base-uncased\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T14:40:21.419876Z","iopub.execute_input":"2025-02-13T14:40:21.420124Z","iopub.status.idle":"2025-02-13T14:42:06.268913Z","shell.execute_reply.started":"2025-02-13T14:40:21.420101Z","shell.execute_reply":"2025-02-13T14:42:06.268181Z"}},"outputs":[{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='565' max='565' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [565/565 01:41, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.210162</td>\n      <td>0.693302</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.186067</td>\n      <td>0.805890</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.196794</td>\n      <td>0.820221</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>0.206575</td>\n      <td>0.815570</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.119100</td>\n      <td>0.213183</td>\n      <td>0.821367</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n        Term       0.65      0.74      0.69      4022\n\n   micro avg       0.65      0.74      0.69      4022\n   macro avg       0.65      0.74      0.69      4022\nweighted avg       0.65      0.74      0.69      4022\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n        Term       0.79      0.82      0.81      4022\n\n   micro avg       0.79      0.82      0.81      4022\n   macro avg       0.79      0.82      0.81      4022\nweighted avg       0.79      0.82      0.81      4022\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n        Term       0.82      0.82      0.82      4022\n\n   micro avg       0.82      0.82      0.82      4022\n   macro avg       0.82      0.82      0.82      4022\nweighted avg       0.82      0.82      0.82      4022\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n        Term       0.81      0.83      0.82      4022\n\n   micro avg       0.81      0.83      0.82      4022\n   macro avg       0.81      0.83      0.82      4022\nweighted avg       0.81      0.83      0.82      4022\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n        Term       0.82      0.83      0.82      4022\n\n   micro avg       0.82      0.83      0.82      4022\n   macro avg       0.82      0.83      0.82      4022\nweighted avg       0.82      0.83      0.82      4022\n\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"conv1d\",\n    learning_rate =1e-4,\n    per_device_train_batch_size =16,\n    per_device_eval_batch_size =16,\n    num_train_epochs =10,\n    weight_decay =0.01,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True\n)\n\ntrainer = Trainer(\n    model=model_conv1d ,\n    args=training_args ,\n    train_dataset=preprocessed_ds[\"train\"],\n    eval_dataset=preprocessed_ds[\"test\"],\n    processing_class=tokenizer ,\n    data_collator=data_collator ,\n    compute_metrics=compute_metrics ,\n)\n\ntrainer.train()\ntrainer.save_model(\"abte-restaurants-conv1d\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T15:09:17.082972Z","iopub.execute_input":"2025-02-13T15:09:17.083367Z","iopub.status.idle":"2025-02-13T15:10:57.776833Z","shell.execute_reply.started":"2025-02-13T15:09:17.083336Z","shell.execute_reply":"2025-02-13T15:10:57.776089Z"}},"outputs":[{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1130' max='1130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1130/1130 01:39, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.465517</td>\n      <td>0.581780</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.392090</td>\n      <td>0.604575</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.374261</td>\n      <td>0.600605</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>0.490846</td>\n      <td>0.626244</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.086400</td>\n      <td>0.453762</td>\n      <td>0.614678</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.086400</td>\n      <td>0.426093</td>\n      <td>0.639668</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.086400</td>\n      <td>0.416792</td>\n      <td>0.642613</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.086400</td>\n      <td>0.405667</td>\n      <td>0.649864</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.008300</td>\n      <td>0.425405</td>\n      <td>0.643846</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.008300</td>\n      <td>0.446236</td>\n      <td>0.642630</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n        Term       0.61      0.55      0.58      4022\n\n   micro avg       0.61      0.55      0.58      4022\n   macro avg       0.61      0.55      0.58      4022\nweighted avg       0.61      0.55      0.58      4022\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n        Term       0.67      0.55      0.60      4022\n\n   micro avg       0.67      0.55      0.60      4022\n   macro avg       0.67      0.55      0.60      4022\nweighted avg       0.67      0.55      0.60      4022\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n        Term       0.64      0.57      0.60      4022\n\n   micro avg       0.64      0.57      0.60      4022\n   macro avg       0.64      0.57      0.60      4022\nweighted avg       0.64      0.57      0.60      4022\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n        Term       0.68      0.58      0.63      4022\n\n   micro avg       0.68      0.58      0.63      4022\n   macro avg       0.68      0.58      0.63      4022\nweighted avg       0.68      0.58      0.63      4022\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n        Term       0.67      0.57      0.61      4022\n\n   micro avg       0.67      0.57      0.61      4022\n   macro avg       0.67      0.57      0.61      4022\nweighted avg       0.67      0.57      0.61      4022\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n        Term       0.67      0.61      0.64      4022\n\n   micro avg       0.67      0.61      0.64      4022\n   macro avg       0.67      0.61      0.64      4022\nweighted avg       0.67      0.61      0.64      4022\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n        Term       0.65      0.63      0.64      4022\n\n   micro avg       0.65      0.63      0.64      4022\n   macro avg       0.65      0.63      0.64      4022\nweighted avg       0.65      0.63      0.64      4022\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n        Term       0.68      0.63      0.65      4022\n\n   micro avg       0.68      0.63      0.65      4022\n   macro avg       0.68      0.63      0.65      4022\nweighted avg       0.68      0.63      0.65      4022\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n        Term       0.66      0.62      0.64      4022\n\n   micro avg       0.66      0.62      0.64      4022\n   macro avg       0.66      0.62      0.64      4022\nweighted avg       0.66      0.62      0.64      4022\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n        Term       0.66      0.63      0.64      4022\n\n   micro avg       0.66      0.63      0.64      4022\n   macro avg       0.66      0.63      0.64      4022\nweighted avg       0.66      0.63      0.64      4022\n\n","output_type":"stream"}],"execution_count":72},{"cell_type":"code","source":"from transformers import pipeline\n\ntoken_classifier = pipeline(\n    model=\"thainq107/abte-restaurants-distilbert-base-uncased\",\n    aggregation_strategy=\"simple\"\n)\n\ntest_sentence = 'The bread is top notch as well'\nresults = token_classifier(test_sentence)\nresults","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T14:43:07.907949Z","iopub.execute_input":"2025-02-13T14:43:07.908250Z","iopub.status.idle":"2025-02-13T14:43:16.671162Z","shell.execute_reply.started":"2025-02-13T14:43:07.908228Z","shell.execute_reply":"2025-02-13T14:43:16.670450Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/712 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc8ae0e1efe244bf8a7caee468039179"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/265M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"524e889dd53a4b239dce6cee7cc8e0d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.23k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd53c9cbdcd843beac9b4b4b58ebccf0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"398919f83bc044d78e8bc2d643cce791"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"803d1688a1214c679d0b812ed7ce4058"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc47bc113afd423f8ca4e5f287f63b6a"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"[{'entity_group': 'Term',\n  'score': 0.90669304,\n  'word': 'bread',\n  'start': 4,\n  'end': 9}]"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"from huggingface_hub import notebook_login\nnotebook_login()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T14:43:16.672093Z","iopub.execute_input":"2025-02-13T14:43:16.672425Z","iopub.status.idle":"2025-02-13T14:43:16.696660Z","shell.execute_reply.started":"2025-02-13T14:43:16.672379Z","shell.execute_reply":"2025-02-13T14:43:16.695652Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9812ffb2b224e8eb74167a457899aca"}},"metadata":{}}],"execution_count":21},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"!huggingface-cli repo create abte-restaurants-conv1d --organization Epsilon123 --type model -y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T15:11:05.958693Z","iopub.execute_input":"2025-02-13T15:11:05.958993Z","iopub.status.idle":"2025-02-13T15:11:16.748734Z","shell.execute_reply.started":"2025-02-13T15:11:05.958970Z","shell.execute_reply":"2025-02-13T15:11:16.747831Z"}},"outputs":[{"name":"stdout","text":"\u001b[90mgit version 2.34.1\u001b[0m\n\u001b[90mgit-lfs/3.0.2 (GitHub; linux amd64; go 1.18.1)\u001b[0m\n\nYou are about to create \u001b[1mEpsilon123/abte-restaurants-conv1d\u001b[0m\n\nYour repo now lives at:\n  \u001b[1mhttps://huggingface.co/Epsilon123/abte-restaurants-conv1d\u001b[0m\n\nYou can clone it locally with the command below, and commit/push as usual.\n\n  git clone https://huggingface.co/Epsilon123/abte-restaurants-conv1d\n\n","output_type":"stream"}],"execution_count":73},{"cell_type":"code","source":"!huggingface-cli upload Epsilon123/abte-restaurants-conv1d abte-restaurants-conv1d","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T15:11:16.750172Z","iopub.execute_input":"2025-02-13T15:11:16.750461Z","iopub.status.idle":"2025-02-13T15:11:26.720887Z","shell.execute_reply.started":"2025-02-13T15:11:16.750437Z","shell.execute_reply":"2025-02-13T15:11:26.719751Z"}},"outputs":[{"name":"stdout","text":"Consider using `hf_transfer` for faster uploads. This solution comes with some limitations. See https://huggingface.co/docs/huggingface_hub/hf_transfer for more details.\nStart hashing 7 files.\nFinished hashing 7 files.\ntraining_args.bin:   0%|                            | 0.00/5.30k [00:00<?, ?B/s]\nmodel.safetensors:   0%|                             | 0.00/136M [00:00<?, ?B/s]\u001b[A\n\nUpload 2 LFS files:   0%|                                 | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\nmodel.safetensors:   1%|▏                    | 918k/136M [00:00<00:16, 8.28MB/s]\u001b[A\ntraining_args.bin: 100%|███████████████████| 5.30k/5.30k [00:00<00:00, 16.1kB/s]\u001b[A\n\nmodel.safetensors:   8%|█▋                  | 11.3M/136M [00:00<00:05, 21.2MB/s]\u001b[A\nmodel.safetensors:  11%|██▏                 | 15.2M/136M [00:00<00:04, 25.5MB/s]\u001b[A\nmodel.safetensors:  13%|██▋                 | 18.0M/136M [00:01<00:08, 14.7MB/s]\u001b[A\nmodel.safetensors:  20%|███▉                | 26.6M/136M [00:01<00:06, 15.8MB/s]\u001b[A\nmodel.safetensors:  22%|████▍               | 29.9M/136M [00:01<00:06, 17.3MB/s]\u001b[A\nmodel.safetensors:  23%|████▋               | 32.0M/136M [00:02<00:08, 12.2MB/s]\u001b[A\nmodel.safetensors:  31%|██████▏             | 41.9M/136M [00:02<00:04, 19.8MB/s]\u001b[A\nmodel.safetensors:  33%|██████▌             | 44.3M/136M [00:02<00:05, 15.8MB/s]\u001b[A\nmodel.safetensors:  35%|███████             | 48.0M/136M [00:03<00:06, 13.0MB/s]\u001b[A\nmodel.safetensors:  47%|█████████▍          | 64.0M/136M [00:03<00:04, 16.6MB/s]\u001b[A\nmodel.safetensors:  59%|███████████▋        | 80.0M/136M [00:04<00:02, 24.4MB/s]\u001b[A\nmodel.safetensors:  70%|██████████████      | 96.0M/136M [00:05<00:01, 20.6MB/s]\u001b[A\nmodel.safetensors:  75%|███████████████▊     | 103M/136M [00:05<00:01, 23.3MB/s]\u001b[A\nmodel.safetensors:  79%|████████████████▌    | 108M/136M [00:05<00:01, 23.2MB/s]\u001b[A\nmodel.safetensors:  82%|█████████████████▎   | 112M/136M [00:05<00:01, 19.7MB/s]\u001b[A\nmodel.safetensors: 100%|█████████████████████| 136M/136M [00:06<00:00, 21.0MB/s]\u001b[A\n\n\nUpload 2 LFS files: 100%|█████████████████████████| 2/2 [00:06<00:00,  3.36s/it]\u001b[A\u001b[A\nhttps://huggingface.co/Epsilon123/abte-restaurants-conv1d/tree/main/.\n","output_type":"stream"}],"execution_count":74},{"cell_type":"code","source":"from transformers import pipeline\n\ntoken_classifier = pipeline(\n    \"token-classification\",  # Specify the task\n    model=\"Epsilon123/abte-restaurants-distilbert-base-uncased\",  # Your model's repository ID\n    aggregation_strategy=\"simple\" # Or your preferred strategy\n)\n\ntest_sentence = \"\"\"To be completely fair , the only redeeming factor was the food , which was above average , but could \"nt\" make up for all the other deficiencies of Teodora .\"\"\"\nresults = token_classifier(test_sentence)\nprint(results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T16:09:14.807312Z","iopub.execute_input":"2025-02-13T16:09:14.807616Z","iopub.status.idle":"2025-02-13T16:09:15.060445Z","shell.execute_reply.started":"2025-02-13T16:09:14.807591Z","shell.execute_reply":"2025-02-13T16:09:15.059722Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"[{'entity_group': 'Term', 'score': 0.84177595, 'word': 'food', 'start': 58, 'end': 62}]\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"## Aspect Term Sentiment Classification","metadata":{}},{"cell_type":"code","source":"from seqeval.metrics import accuracy_score\nfrom datasets import load_dataset\nfrom transformers import (AutoTokenizer,\n                          DataCollatorForTokenClassification,\n                          AutoModelForSequenceClassification)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T15:55:57.836980Z","iopub.execute_input":"2025-02-13T15:55:57.837295Z","iopub.status.idle":"2025-02-13T15:56:19.491637Z","shell.execute_reply.started":"2025-02-13T15:55:57.837269Z","shell.execute_reply":"2025-02-13T15:56:19.490882Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"ds = load_dataset(\"thainq107/abte-restaurants\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T15:56:19.492522Z","iopub.execute_input":"2025-02-13T15:56:19.493124Z","iopub.status.idle":"2025-02-13T15:56:44.550454Z","shell.execute_reply.started":"2025-02-13T15:56:19.493084Z","shell.execute_reply":"2025-02-13T15:56:44.549818Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/454 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"052f667e83364ca9be1314e3496bd839"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/183k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b915c388de84ae683532f637495acaf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/61.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a45e2f152f5c44268f841461e74514be"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/3602 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b35e182e8b724ba0bd6fdf72783ef333"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1119 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8145b4ed9e0540ae81fa097038c21025"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"len(ds['train'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T16:28:07.933628Z","iopub.execute_input":"2025-02-13T16:28:07.934005Z","iopub.status.idle":"2025-02-13T16:28:07.939153Z","shell.execute_reply.started":"2025-02-13T16:28:07.933976Z","shell.execute_reply":"2025-02-13T16:28:07.938460Z"}},"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"3602"},"metadata":{}}],"execution_count":42},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")\n\ndef tokenize_and_align_labels(examples):\n    sentences, sentence_tags = [], []\n    labels = []\n    for tokens , pols in zip(examples['Tokens'], examples['Polarities']):\n        # tokens = tokens.replace(\"'\", \"\").strip(\"][\").split(', ')\n        # pols = pols.strip('][').split(', ')\n\n        bert_tokens = []\n        bert_att = []\n        pols_label = 0\n        for i in range(len(tokens)):\n            t = tokenizer.tokenize(tokens[i])\n            bert_tokens += t\n            if int(pols[i]) != -1:\n                bert_att += t\n                pols_label = int(pols[i])\n\n        sentences.append(\" \".join(bert_tokens))\n        sentence_tags.append(\" \".join(bert_att))\n        labels.append(pols_label)\n\n    tokenized_inputs = tokenizer(sentences , sentence_tags , padding=True , truncation=True , return_tensors=\"pt\")\n    tokenized_inputs['labels'] = labels\n    return tokenized_inputs\n\npreprocessed_ds = ds.map(tokenize_and_align_labels, batched = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T15:56:44.632488Z","iopub.execute_input":"2025-02-13T15:56:44.632739Z","iopub.status.idle":"2025-02-13T15:56:49.607258Z","shell.execute_reply.started":"2025-02-13T15:56:44.632717Z","shell.execute_reply":"2025-02-13T15:56:49.606350Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5cf5732a070b4d7199abe23812d6472c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0473f99594cd434ebc1f1e99adb5a315"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76c7a90a74c643519d9db45e5c4a23b6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1d8f18cec7e486a9a05ccda8e677d31"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3602 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dde090966b1a4b7ebdb54e29f7793706"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1119 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5bdad5878695495590af422f5135a79e"}},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"import evaluate\nimport numpy as np\n\naccuracy = evaluate.load(\"accuracy\")\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions , axis =1)\n    return accuracy.compute(predictions=predictions , references=labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T15:56:49.609311Z","iopub.execute_input":"2025-02-13T15:56:49.609550Z","iopub.status.idle":"2025-02-13T15:56:51.417689Z","shell.execute_reply.started":"2025-02-13T15:56:49.609524Z","shell.execute_reply":"2025-02-13T15:56:51.416892Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc11062da47f4a8ba60278ca562e1c34"}},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"id2label = {0: 'Negative', 1: 'Neutral', 2: 'Positive'}\nlabel2id = {'Negative': 0, 'Neutral': 1, 'Positive': 2}\n\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    \"distilbert/distilbert-base-uncased\", num_labels =3, id2label=id2label , label2id=label2id\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T15:56:51.418608Z","iopub.execute_input":"2025-02-13T15:56:51.418867Z","iopub.status.idle":"2025-02-13T15:56:53.106354Z","shell.execute_reply.started":"2025-02-13T15:56:51.418845Z","shell.execute_reply":"2025-02-13T15:56:53.105511Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4e7c259e0724abe96207b014082bc3d"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import os\nfrom transformers import TrainingArguments , Trainer\n\nos.environ['WANDB_DISABLED'] = 'true'\n\ntraining_args = TrainingArguments(\n    output_dir=\"absa-distilbert-base-uncased\",\n    learning_rate =2e-5,\n    per_device_train_batch_size =16,\n    per_device_eval_batch_size =16,\n    num_train_epochs =5,\n    weight_decay =0.01,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True\n)\n\ntrainer = Trainer(\n    model=model ,\n    args=training_args ,\n    train_dataset=preprocessed_ds[\"train\"],\n    eval_dataset=preprocessed_ds[\"test\"],\n    processing_class=tokenizer ,\n    compute_metrics=compute_metrics ,\n)\ntrainer.train()\ntrainer.save_model('bsa-restaurants-distilbert-base-uncased')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T15:56:53.107282Z","iopub.execute_input":"2025-02-13T15:56:53.107596Z","iopub.status.idle":"2025-02-13T15:59:53.844399Z","shell.execute_reply.started":"2025-02-13T15:56:53.107563Z","shell.execute_reply":"2025-02-13T15:59:53.843654Z"}},"outputs":[{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='565' max='565' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [565/565 02:55, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.623762</td>\n      <td>0.763181</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.529678</td>\n      <td>0.779267</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.515828</td>\n      <td>0.806077</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>0.494574</td>\n      <td>0.820375</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.516500</td>\n      <td>0.509793</td>\n      <td>0.814120</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"from huggingface_hub import notebook_login\nnotebook_login()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T16:00:35.660696Z","iopub.execute_input":"2025-02-13T16:00:35.661244Z","iopub.status.idle":"2025-02-13T16:00:35.692215Z","shell.execute_reply.started":"2025-02-13T16:00:35.661189Z","shell.execute_reply":"2025-02-13T16:00:35.691128Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4928b448c2624edfae56f56a339781b3"}},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"!huggingface-cli repo create absa-restaurants-distilbert-base-uncased --organization Epsilon123 --type model -y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T16:01:53.484297Z","iopub.execute_input":"2025-02-13T16:01:53.484619Z","iopub.status.idle":"2025-02-13T16:01:54.941269Z","shell.execute_reply.started":"2025-02-13T16:01:53.484590Z","shell.execute_reply":"2025-02-13T16:01:54.940127Z"}},"outputs":[{"name":"stdout","text":"\u001b[90mgit version 2.34.1\u001b[0m\n\u001b[90mgit-lfs/3.0.2 (GitHub; linux amd64; go 1.18.1)\u001b[0m\n\nYou are about to create \u001b[1mEpsilon123/absa-restaurants-distilbert-base-uncased\u001b[0m\n\nYour repo now lives at:\n  \u001b[1mhttps://huggingface.co/Epsilon123/absa-restaurants-distilbert-base-uncased\u001b[0m\n\nYou can clone it locally with the command below, and commit/push as usual.\n\n  git clone https://huggingface.co/Epsilon123/absa-restaurants-distilbert-base-uncased\n\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"!huggingface-cli upload Epsilon123/absa-restaurants-distilbert-base-uncased bsa-restaurants-distilbert-base-uncased","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T16:01:57.090646Z","iopub.execute_input":"2025-02-13T16:01:57.091026Z","iopub.status.idle":"2025-02-13T16:02:09.241949Z","shell.execute_reply.started":"2025-02-13T16:01:57.090992Z","shell.execute_reply":"2025-02-13T16:02:09.240893Z"}},"outputs":[{"name":"stdout","text":"Consider using `hf_transfer` for faster uploads. This solution comes with some limitations. See https://huggingface.co/docs/huggingface_hub/hf_transfer for more details.\nStart hashing 7 files.\nFinished hashing 7 files.\nmodel.safetensors:   0%|                             | 0.00/268M [00:00<?, ?B/s]\ntraining_args.bin:   0%|                            | 0.00/5.37k [00:00<?, ?B/s]\u001b[A\n\ntraining_args.bin: 100%|███████████████████| 5.37k/5.37k [00:00<00:00, 15.9kB/s]\u001b[A\u001b[A\nmodel.safetensors: 100%|█████████████████████| 268M/268M [00:09<00:00, 29.0MB/s]\n\n\nUpload 2 LFS files: 100%|█████████████████████████| 2/2 [00:09<00:00,  4.73s/it]\u001b[A\u001b[A\nhttps://huggingface.co/Epsilon123/absa-restaurants-distilbert-base-uncased/tree/main/.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"from transformers import pipeline\n\ntoken_classifier = pipeline(\n    \"token-classification\",  # Specify the task\n    model=\"Epsilon123/abte-restaurants-distilbert-base-uncased\",\n    aggregation_strategy=\"simple\"\n)\n\nclassifier = pipeline(\n    \"text-classification\",\n    model=\"Epsilon123/absa-restaurants-distilbert-base-uncased\",\n\n)\n\ntest_sentence = 'The food is terrible'\nresults = token_classifier(test_sentence)\nsentence_tags = \" \".join([ result['word'] for result in results ])\n\npred_label = classifier(f'{test_sentence} [SEP] {sentence_tags}')\nsentence_tags, pred_label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T16:48:32.273346Z","iopub.execute_input":"2025-02-13T16:48:32.273676Z","iopub.status.idle":"2025-02-13T16:48:32.800511Z","shell.execute_reply.started":"2025-02-13T16:48:32.273648Z","shell.execute_reply":"2025-02-13T16:48:32.799594Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\nDevice set to use cuda:0\n","output_type":"stream"},{"execution_count":71,"output_type":"execute_result","data":{"text/plain":"('food', [{'label': 'Negative', 'score': 0.8919645547866821}])"},"metadata":{}}],"execution_count":71},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModelForTokenClassification, AutoTokenizer\n\nmodel_name = \"Epsilon123/absa-restaurants-distilbert-base-uncased\"\n\nmodel = AutoModelForTokenClassification.from_pretrained(model_name)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\n# Now you can use the model and tokenizer directly:\ninputs = tokenizer(\"The food was amazing, but the service was slow. [SEP] food service\", return_tensors=\"pt\")\noutputs = model(**inputs)\npredictions = torch.argmax(outputs.logits, dim=-1)\n\n# Process the predictions as needed...","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T16:35:03.890705Z","iopub.execute_input":"2025-02-13T16:35:03.891050Z","iopub.status.idle":"2025-02-13T16:35:04.174614Z","shell.execute_reply.started":"2025-02-13T16:35:03.891020Z","shell.execute_reply":"2025-02-13T16:35:04.173670Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T16:38:34.237919Z","iopub.execute_input":"2025-02-13T16:38:34.238204Z","iopub.status.idle":"2025-02-13T16:38:34.247184Z","shell.execute_reply.started":"2025-02-13T16:38:34.238181Z","shell.execute_reply":"2025-02-13T16:38:34.246249Z"}},"outputs":[{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"array([[ 101, 1996, 2833, 2001, 6429, 1010, 2021, 1996, 2326, 2001, 4030,\n        1012,  102, 2833, 2326,  102]])"},"metadata":{}}],"execution_count":55},{"cell_type":"code","source":"tokenizer.decode(inputs['input_ids'][0].cpu().numpy()), predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T16:38:53.705675Z","iopub.execute_input":"2025-02-13T16:38:53.706036Z","iopub.status.idle":"2025-02-13T16:38:53.712695Z","shell.execute_reply.started":"2025-02-13T16:38:53.706007Z","shell.execute_reply":"2025-02-13T16:38:53.711851Z"}},"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"('[CLS] the food was amazing, but the service was slow. [SEP] food service [SEP]',\n tensor([[1, 2, 1, 2, 1, 2, 2, 1, 0, 1, 1, 1, 2, 1, 1, 2]]))"},"metadata":{}}],"execution_count":57},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}